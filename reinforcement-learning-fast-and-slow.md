# Reinforcement Learning, Fast and Slow

This is a review of current state of RL field seemingly slow and not similar to human learning. Text describes that slow learning gives rise to fast learning in reinforcement learning system.

## Episodic Reinforcement Learning

They explain the working of episodic RL and how it is similar to human learning. [They describe] We approximate the valuation of current event not only based on all the experience (biases) but the explicity stored events we ever encountered and use their internal hidden representation alongwith current event encountered.

## Meta Reinforcement Learning

Meta RL was discussed as a biases of all the environmental experience mapped to actions. This helps in further quickly adjusting the connection parameters of learning system to adapt to new unseen but similar situations due to the biases captured relevant to environmental tasks considered. Meta RL's counterpart in connectionist learning is called transfer learning, meta learning, or learning to learn.

As an example, we learn to use a new smartphone quickly if we ever encountered using a smartphone in past. But a newcomer to smartphone technology finds it long time taking process because his/her mind has high variance to this particular task of using a smartphone device. In the former case the user's mind has learned a good biases towards using smartphone and this helps in learning a new smartphone swiftly and this is an epitome example of meta learning in RL.

## Episodic Meta Reinforcement Learning

Later the paper draws a connection between episodic and meta reinforcement learning claiming that we both go with hand-in-hand they tend to leverage the powers of both learning system worlds (episodic memory and meta learning). Episodic Meta RL is made possible using sequencial neural networks such as recurrent neural networks.

## Implications for Psychology and Neuroscience

Finally the paper discusses how psychology and neuroscience can benefit from the research of reinforcement learning.

## My Thoughts

I am new to reinforcement learning coming from neural networks research world. And I have seen Numenta Inc. working on decrypting the neocortex of brain which is mainly responsible for whatever the f*** we do. And since they are actually finding the true principles of intelligence I don't think Deep Reinforcement Learning is some that important field [from POV of true intelligence] from which computational neuroscience should get inspired from. But the inspiration should be the other way. 

Just because the paper is from researchers from DeepMind and they've been working on Deep RL kind of since start & their paper will be given a lot of attention and value. I felt like they were trying to save Deep RL field from sinking and just to keep this field relevant (because people felt it requires lots of data and exponentially more time of reward learning than humans to learn a particular task) as DeepMind's main goal is Deep RL and they can't go irrelevant in this era or they'll have nothing to do if everybody finds out Deep RL is not the answer to human intelligence. 

BTW same thoughts goes for OpenAI which has now become ClosedAI. They are also trying to create publicity and keeping themselves relevant. They published a paper describing small GPT-2 model for realistic text generation from just headings and wrote the large model release can be "dangerous" like WTF didn't Ian Goodfellow described Generative Adversarial Nets to the world? And the same day they published a paper on Distill describing the need for AI safety engineer in this era. It definitely seemed to be planned.

P.S. These companies need to stop buzzing and focus on finding true principles underlying the intelligence. According to me Numenta Inc. is the only company truly focussing on finding true human intelligence on Earth.